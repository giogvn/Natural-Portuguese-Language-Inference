{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, DatasetFilter\n",
    "api = HfApi()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    "\n",
    "### #1 Finding Natural Language Inference (NLI) datasets in Portuguese <br>\n",
    "\n",
    "To accomplish such goal, I'll be using two methods from the HFApi class that makes it possible to search for datasets based on some DatasetFilters Objects. These filters allow you to search based on some criteria of which I will use the following:\n",
    "- *benchmark*: NLI famous datasets\n",
    "- *language*: a critical search criteria that will be used to filer only datasets written in the Portuguese Language\n",
    "- *task_categories*: a critical search criteria that will be used to filter only datasets related to the task classification task\n",
    "- *task_id*: a critical search criteria that will be used to filter only datasets related to the natural language inference task**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''Benchmark Filter'''\n",
    "benchmarks = ['glue', 'mnli', 'assin', 'assin2', 'sick', 'sick-br', \n",
    "              'snli', 'multi_nli', 'xtreme', 'hans']\n",
    "filter = DatasetFilter(benchmark=benchmarks, language = 'pt')\n",
    "benchmarked_datasets = list(iter(api.list_datasets(filter=filter)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''Taks Category Filter'''\n",
    "task_category = 'text-classification'\n",
    "filter = DatasetFilter(task_categories=task_category, language='pt')\n",
    "text_classification_datasets = list(iter(api.list_datasets(filter=filter)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''Taks ID Filter'''\n",
    "task_id= 'natural-language-inference'\n",
    "filter = DatasetFilter(task_ids=task_id, language='pt')\n",
    "nli_datasets = list(iter(api.list_datasets(filter=filter)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
