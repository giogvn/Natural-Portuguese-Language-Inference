output_dir: training_checkpoints
overwrite_output_dir: 1
do_train: 0
do_eval: 1
do_predict: 0
evaluation_strategy: steps
report_to: wandb
eval_steps: 100
save_strategy: steps
save_steps: 100
save_total_limit: 2
metric_for_best_model: eval_loss
greater_is_better: 0
logging_steps: 100
remove_unused_columns: 1
fp16: 1
warmup_ratio: 0.1
learning_rate: 0.00001
per_device_train_batch_size: 16
weight_decay: 0.01
num_train_epochs: 3
adam_epsilon: 0.000001
adam_beta1: 0.9
adam_beta2: 0.999